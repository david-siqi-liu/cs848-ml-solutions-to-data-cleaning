Paper Title: Uni-Detect: A Unified Approach to Automated Error Detection in Tables

1. Overall Rating
[ ] Strong Accept
[x] Accept
[ ] Weak Accept
[ ] Weak Reject
[ ] Reject


2. Primary Focus
[x] Theory
[x] Algorithmic Improvement
[ ] Systems
[x] Implementation
[ ] Empirical Evaluation


3. Novelty
[x] High
[ ] Medium
[ ] Low


4. Technical Depth
[ ] High
[x] Medium
[ ] Low


5. Presentation
[x] Very good
[ ] Adequate
[ ] Not good


6. Reviewer Confidence
[x] High
[ ] Medium
[ ] Low


7. Justification of Decision (one paragraph)

This paper presents a novel approach to unsupervised, configuration-free error detection. Using a "what-if"/local-perturbations likelihood ratio test, the algorithm that this paper presents is applicable to some of the most representative data errors (numeric outliers, spelling mistakes, uniqueness, FD constraints). It is intuitive, and yet yields great results compared to some other industry standard algorithms. However, similar to other configuration-free error detection approaches (e.g. Raha), this algorithm does not work on domain-specific tables, e.g. ones with CFDs. In addition, this approach relies on a "ground-truth" table called "T". Nevertheless, the idea behind this paper is so novel, intuitive and not-so-difficult to implement that it deserves an "Accept" rating.


8. Detailed comments (please number each comment) 

- Relies completely on the accuracy of the "ground-truth" table T. How do we know these 600 million columns are clean?
- Does not apply to any domain-specific data, so CFDs wouldn't work at all
- What is a good epsilon (number/percentage of rows to remove)? What about alpha?

# Notes

- Bad if too many errors